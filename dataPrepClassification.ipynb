{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b29ec8ee-695d-4036-beed-70dfe9c73cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil \n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import random \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "06d43b6b-bf70-4b1a-b9d9-f75d876d5d3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def augment_image(image, hue_shift, saturation_scale, brightness_scale):\n",
    "    # Convert the image from BGR to HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply augmentation\n",
    "    hsv_image[:, :, 0] = (hsv_image[:, :, 0] + hue_shift) % 180\n",
    "    hsv_image[:, :, 1] = np.clip(saturation_scale * hsv_image[:, :, 1], 0, 255)\n",
    "    hsv_image[:, :, 2] = np.clip(brightness_scale * hsv_image[:, :, 2], 0, 255)\n",
    "\n",
    "    # Convert the augmented image back to BGR\n",
    "    augmented_image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return augmented_image\n",
    "\n",
    "# Set augmentation parameters\n",
    "hue_shifts = [20, -20, 0, 10, 15]  # Degrees to shift the hue\n",
    "saturation_scales = [1.5, 0.5, 1.0, 1.2, 1.4]  # Scaling factor for saturation\n",
    "brightness_scales = [1.2, 1.0, 0.8, 1.0, 1.2]  # Scaling factor for brightness\n",
    "\n",
    "# Adjusting the function to ensure the default sizes sum up to 1.0\n",
    "def split_img_paths(img_paths, train_size=0.7, val_size=0.2, test_size=0.1):\n",
    "    \"\"\"\n",
    "    Split a list of image paths into training, validation, and test sets.\n",
    "\n",
    "    Parameters:\n",
    "    img_paths (list): List of image paths.\n",
    "    train_size (float): Proportion of the dataset to include in the train split.\n",
    "    val_size (float): Proportion of the dataset to include in the validation split.\n",
    "    test_size (float): Proportion of the dataset to include in the test split.\n",
    "\n",
    "    Returns:\n",
    "    train_paths, val_paths, test_paths: Lists of image paths for training, validation, and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # if train_size + val_size + test_size != 1.0:\n",
    "    #     raise ValueError(\"Train, validation, and test sizes must sum to 1.\")\n",
    "\n",
    "    # Splitting the data into training and temp (val + test) sets\n",
    "    train_paths, temp_paths = train_test_split(img_paths, train_size=train_size)\n",
    "\n",
    "    # Splitting the temp set into validation and test sets\n",
    "    val_size_adjusted = val_size / (val_size + test_size)  # Adjusting validation size for the temp set\n",
    "    val_paths, test_paths = train_test_split(temp_paths, train_size=val_size_adjusted)\n",
    "\n",
    "    return train_paths, val_paths, test_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8486581e-943e-4987-b767-3ea9d5f1341a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = ['lateralRaises', 'squats', 'pushups']\n",
    "img_dir = \"C://Users//mirza//ASU//MS_master_folder//semester_2//cenembedded//finalProject//customDataset_org//\"\n",
    "output_dir = 'data/'\n",
    "for each in classes:\n",
    "    for every in [\"train\", 'val', 'test']:\n",
    "        os.makedirs( output_dir + '/' + every + '/' + each, )\n",
    "modes = [\"train\", 'val', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f24309c5-c085-43a9-8704-6c081e64d412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for each_cls in classes:\n",
    "    img_files = glob.glob( img_dir + '/' + each_cls + '/*/*.jpg')\n",
    "    # print( len( img_files))\n",
    "    random.shuffle(img_files)\n",
    "    train_img_files, val_img_files, test_img_files = split_img_paths( img_files)\n",
    "    count = 0\n",
    "    for eachMode in [train_img_files, val_img_files, test_img_files]:\n",
    "        for idx, each_path in enumerate( eachMode):        \n",
    "            img = cv2.imread( each_path)        \n",
    "            for i, (hue_shift, saturation_scale, brightness_scale) in enumerate(zip(hue_shifts, saturation_scales, brightness_scales)):\n",
    "                augmented_image = augment_image(img, hue_shift, saturation_scale, brightness_scale)\n",
    "                cv2.imwrite( output_dir + modes[count] + '/' + each_cls + '/' + f'augmented_image_{i+1}_{each_cls}_{idx}.jpg', augmented_image)        \n",
    "        count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
